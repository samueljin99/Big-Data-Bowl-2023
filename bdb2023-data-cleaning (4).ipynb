{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nimport time\nimport math\nfrom math import radians\nimport gc\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nimport time\nimport math\nfrom math import radians\nimport gc\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-12-03T03:25:29.277864Z","iopub.execute_input":"2022-12-03T03:25:29.278525Z","iopub.status.idle":"2022-12-03T03:25:29.291805Z","shell.execute_reply.started":"2022-12-03T03:25:29.278474Z","shell.execute_reply":"2022-12-03T03:25:29.290621Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/nfl-big-data-bowl-2023/players.csv\n/kaggle/input/nfl-big-data-bowl-2023/week6.csv\n/kaggle/input/nfl-big-data-bowl-2023/week2.csv\n/kaggle/input/nfl-big-data-bowl-2023/pffScoutingData.csv\n/kaggle/input/nfl-big-data-bowl-2023/week3.csv\n/kaggle/input/nfl-big-data-bowl-2023/week8.csv\n/kaggle/input/nfl-big-data-bowl-2023/games.csv\n/kaggle/input/nfl-big-data-bowl-2023/week5.csv\n/kaggle/input/nfl-big-data-bowl-2023/week7.csv\n/kaggle/input/nfl-big-data-bowl-2023/week1.csv\n/kaggle/input/nfl-big-data-bowl-2023/week4.csv\n/kaggle/input/nfl-big-data-bowl-2023/plays.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_df_counts(df: pd.DataFrame):\n    \"\"\"get the number of unique counts for each column\"\"\"\n    total_count = len(df)\n    df_unique = pd.DataFrame.from_records([(col, str(df[col].dtype), df[col].count(), total_count-df[col].count(), df[col].nunique()) for col in df.columns],\n                                          columns=['column_name', 'dtype', 'non_null_count', 'null_count', 'num_unique'])\n    mem = df.memory_usage()\n    mem_usage = pd.DataFrame(mem, columns=['usage']).reset_index().rename(columns={'index': 'column_name'})\n    mem_usage = mem_usage.assign(usage_mb = mem_usage.usage/1024**2)\n    mem_usage.drop(columns=['usage'], inplace=True)\n    df_counts = mem_usage.merge(df_unique).sort_values(by='usage_mb', ascending=False)\n    \n    print(f'memory usage: {sum(mem)/1024**2:.1f}MB')\n    return df_counts\n\ndef reduce_mem_usage(df, category_limit: int = 128):\n    \"\"\"reduce memory usage\"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            if not (str(col_type).startswith('int') or str(col_type).startswith('float')):\n                continue\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type).startswith('int'):\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int64)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            elif str(col_type).startswith('float'):\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float32)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)#\n                else:\n                    df[col] = df[col].astype(np.float64)\n#         else:\n#             if df[col].nunique() <= category_limit:\n#                 df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(f'memory usage decreased by {100*(start_mem - end_mem)/start_mem:.1f}, final size {end_mem:.1f} MB')\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-12-03T03:25:30.275808Z","iopub.execute_input":"2022-12-03T03:25:30.276927Z","iopub.status.idle":"2022-12-03T03:25:30.297144Z","shell.execute_reply.started":"2022-12-03T03:25:30.276874Z","shell.execute_reply":"2022-12-03T03:25:30.296127Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def import_data(d):\n    df = pd.read_csv(d)\n    df = reduce_mem_usage(df)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-12-03T03:25:31.256917Z","iopub.execute_input":"2022-12-03T03:25:31.257797Z","iopub.status.idle":"2022-12-03T03:25:31.263854Z","shell.execute_reply.started":"2022-12-03T03:25:31.257743Z","shell.execute_reply":"2022-12-03T03:25:31.262890Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def mergeData(df):\n    print(\"Merging data...\")\n    games = reduce_mem_usage(pd.read_csv(\"../input/nfl-big-data-bowl-2023/games.csv\"))\n    plays = reduce_mem_usage(pd.read_csv(\"../input/nfl-big-data-bowl-2023/plays.csv\"))\n    pff = reduce_mem_usage(pd.read_csv(\"../input/nfl-big-data-bowl-2023/pffScoutingData.csv\"))\n    players = reduce_mem_usage(pd.read_csv(\"../input/nfl-big-data-bowl-2023/players.csv\"))\n    players.drop(['height','weight','birthDate', 'collegeName'], axis=1, inplace=True)\n    players['nflId'] = players['nflId'].astype(float)\n    df = pd.merge(df,games, how = 'left',left_on=['gameId'], right_on=['gameId'])\n    df['PlayerTeam'] = np.where(df['team'] == 'home', df['homeTeamAbbr'], df['visitorTeamAbbr'])\n    df = df.drop(['homeTeamAbbr','visitorTeamAbbr'], axis=1)\n    df = pd.merge(df, plays, how = 'left', left_on = ['gameId', 'playId'], right_on = ['gameId', 'playId'])\n    df = pd.merge(df, pff, how = 'left', left_on=['gameId', 'playId', 'nflId'], right_on=['gameId', 'playId', 'nflId'])\n    df= pd.merge(df, players, how = 'left', left_on = ['nflId'], right_on = ['nflId'])\n    \n    print(f'memory: {sum(df.memory_usage())/ 1024**2:.1f}MB')\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-12-03T03:25:32.156026Z","iopub.execute_input":"2022-12-03T03:25:32.156854Z","iopub.status.idle":"2022-12-03T03:25:32.170270Z","shell.execute_reply.started":"2022-12-03T03:25:32.156811Z","shell.execute_reply":"2022-12-03T03:25:32.169083Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def Standardize(D):\n    print(\"Standardizing data...\")\n    D[\"ToLeft\"] = D['playDirection'] == 'left'\n    D['onOffense'] = D.team == D.possessionTeam\n    D['absoluteYardlineNumber_std'] = D['absoluteYardlineNumber']\n    D.loc[D.ToLeft, 'absoluteYardlineNumber_std'] = 120 - D.absoluteYardlineNumber_std\n    #standardize x-coordinate\n    D[\"X_std\"] = D.x\n    D.loc[D.ToLeft, \"X_std\"] = 120 - D.loc[D.ToLeft, \"x\"]\n    #standardize y-coordinate\n    D[\"Y_std\"] = D.y\n    D.loc[D.ToLeft, \"Y_std\"] = 160/3 - D.loc[D.ToLeft, \"y\"]\n    #standardize orientation in degrees and radians (0 degrees is point straight at opposing end zone)\n    D[\"o_deg\"] = D.o\n    D[\"o_deg_std\"] = np.mod(D.o-90, 360)\n    D.loc[D.ToLeft, \"o_deg_std\"] = np.mod(D.loc[D.ToLeft, \"o_deg_std\"] + 180, 360)\n    D[\"o_rad\"] = np.mod(D.o, 360) * math.pi/180\n    D[\"o_rad_std\"] = np.mod(D.o_rad - math.pi/2, 2*math.pi)\n    D.loc[D.ToLeft, \"o_rad_std\"] = np.mod(D.loc[D.ToLeft, \"o_rad_std\"] + math.pi, 2 * math.pi)\n    #standardize direction in degrees and radians (0 degrees is point straight at opposing end zone)\n    D[\"dir_deg\"] = D.dir\n    D[\"dir_deg_std\"] = np.mod(D.dir-90, 360)\n    D.loc[D.ToLeft, \"dir_deg_std\"] = np.mod(D.loc[D.ToLeft, \"dir_deg_std\"] + 180, 360)\n    D[\"dir_rad\"] = np.mod(D.dir, 360) * math.pi/180\n    D[\"dir_rad_std\"] = np.mod(D.dir_rad - math.pi/2, 2*math.pi)\n    D.loc[D.ToLeft, \"dir_rad_std\"] = np.mod(D.loc[D.ToLeft, \"dir_rad_std\"] + math.pi, 2 * math.pi)\n    D[\"MPH\"] = D.s * 2.23694\n    #distance to opposing end zone\n    D[\"end_distance\"] = 110 - D.X_std\n    # speed in x and y vectors\n    D[\"speed_x\"] = round(D.s * np.cos(D.dir_rad_std), 2)\n    D[\"speed_y\"] = round(D.s * np.sin(D.dir_rad_std), 2)\n    return D","metadata":{"execution":{"iopub.status.busy":"2022-12-03T03:25:33.062624Z","iopub.execute_input":"2022-12-03T03:25:33.063538Z","iopub.status.idle":"2022-12-03T03:25:33.078134Z","shell.execute_reply.started":"2022-12-03T03:25:33.063494Z","shell.execute_reply":"2022-12-03T03:25:33.076702Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def DistanceLos(D):\n    D['dist_los'] = D.X_std - D.absoluteYardlineNumber_std\n    return D","metadata":{"execution":{"iopub.status.busy":"2022-12-03T03:25:33.955786Z","iopub.execute_input":"2022-12-03T03:25:33.956219Z","iopub.status.idle":"2022-12-03T03:25:33.963056Z","shell.execute_reply.started":"2022-12-03T03:25:33.956184Z","shell.execute_reply":"2022-12-03T03:25:33.961310Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def RelativePlayerInfo(D):\n    print(\"Getting relative player info...\")\n    #qb distance\n    qb_frames = D.query('pff_positionLinedUp == \"QB\"')[['gameId','playId','frameId', 'X_std', 'Y_std','o_rad_std','dir_rad_std']]\n    qb_frames = qb_frames.rename(columns = {'X_std':'QB_X', 'Y_std':'QB_Y','o_rad_std': 'QB_o_rad_std','dir_rad_std':'QB_dir_rad_std'})\n    D = pd.merge(D, qb_frames, how = 'left', left_on=['gameId', 'playId', 'frameId'], right_on=['gameId', 'playId', 'frameId'])\n    D['QB_dx'] = D.X_std-D.QB_X\n    D['QB_dy'] = D.Y_std-D.QB_Y\n    D['dist_QB'] = np.sqrt(D.QB_dx**2+D.QB_dy**2)\n    #football distance    \n    football_frames = D.query('team == \"football\"')[['gameId','playId','frameId', 'X_std', 'Y_std',]]\n    football_frames = football_frames.rename(columns = {'X_std':'football_X', 'Y_std':'football_Y'})\n    D= pd.merge(D, football_frames, how = 'left', left_on=['gameId', 'playId', 'frameId'], right_on=['gameId', 'playId', 'frameId'])\n    D['ball_dx'] = D.X_std-D.football_X\n    D['ball_dy'] = D.Y_std-D.football_Y\n    D['dist_ball'] = np.sqrt(D.ball_dx**2+D.ball_dy**2)\n    #blocked player info\n    D_blockingmerge = D[['gameId', 'playId', 'nflId', 'frameId',\n        'officialPosition', 'pff_role', 'pff_positionLinedUp','pff_nflIdBlockedPlayer', 'X_std', 'Y_std', 'o_deg_std', \n        'o_rad_std', 'dir_deg_std','dir_rad_std','MPH','speed_y','speed_x']]\n    D_blockingmerge = D_blockingmerge.query('nflId == nflId')\n    D_blockingmerge.columns = ['blocked_' + str(col) for col in D_blockingmerge.columns]\n    D = pd.merge(D, D_blockingmerge, how = 'left', \n                               left_on = ['gameId', 'playId', 'frameId', 'pff_nflIdBlockedPlayer'], \n                               right_on=['blocked_gameId', 'blocked_playId', 'blocked_frameId', 'blocked_nflId'])\n    D = D.drop(['blocked_pff_nflIdBlockedPlayer', 'blocked_frameId', 'blocked_nflId', 'blocked_playId', 'blocked_gameId'], axis = 1)\n    D['blocked_dx'] = D.X_std - D.blocked_X_std\n    D['blocked_dy'] = D.Y_std - D.blocked_Y_std\n    D['dist_blocked'] = np.sqrt(D.blocked_dx**2 + D.blocked_dy**2)\n    \n    \n    \n    return D\n    \n    \n    \n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-03T03:25:34.837706Z","iopub.execute_input":"2022-12-03T03:25:34.838142Z","iopub.status.idle":"2022-12-03T03:25:34.852659Z","shell.execute_reply.started":"2022-12-03T03:25:34.838108Z","shell.execute_reply":"2022-12-03T03:25:34.851084Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# weeks = {1,2,3,4,5,6,7,8}\nweeks = range(1,9)\n\nfinaldf_list = []\nfor n in tqdm(weeks):\n    start = time.process_time()\n    print('Week ' + str(n))\n    filename = '../input/nfl-big-data-bowl-2023/week' + str(n) + '.csv'\n    Original = import_data(filename)\n    print('Merge-------')\n    df = mergeData(Original)\n    print('Standardize-------')\n    Finaldf = Standardize(df)\n\n    Relevantdf = Finaldf[['gameDate', 'gameTimeEastern', 'week','gameId', 'playId', 'frameId', 'nflId', 'displayName',\n       'onOffense','team','officialPosition','playDirection', 'x', 'y', 's', 'a', 'dis', 'o', 'dir', 'ToLeft', 'X_std', 'Y_std',\n       'o_deg', 'o_deg_std', 'o_rad', 'o_rad_std', 'dir_deg', 'dir_deg_std',\n       'dir_rad', 'dir_rad_std', 'MPH','speed_x','speed_y', 'end_distance', 'event',\n       'season', 'PlayerTeam',\n       'playDescription', 'quarter', 'down', 'yardsToGo', 'possessionTeam',\n       'defensiveTeam', 'yardlineSide', 'yardlineNumber', 'gameClock',\n       'preSnapHomeScore', 'preSnapVisitorScore', 'passResult', 'penaltyYards',\n       'prePenaltyPlayResult', 'playResult', 'foulName1', 'foulNFLId1',\n       'foulName2', 'foulNFLId2', 'foulName3', 'foulNFLId3',\n       'absoluteYardlineNumber','absoluteYardlineNumber_std', 'offenseFormation', 'personnelO',\n       'defendersInBox', 'personnelD', 'dropBackType', 'pff_playAction',\n       'pff_passCoverage', 'pff_passCoverageType', 'pff_role',\n       'pff_positionLinedUp', 'pff_hit', 'pff_hurry', 'pff_sack',\n       'pff_beatenByDefender', 'pff_hitAllowed', 'pff_hurryAllowed',\n       'pff_sackAllowed', 'pff_nflIdBlockedPlayer', 'pff_blockType',\n       'pff_backFieldBlock' ]]\n    \n    \n    Relevantdf = RelativePlayerInfo(Relevantdf)\n    Relevantdf = DistanceLos(Relevantdf)\n    Relevantdf = reduce_mem_usage(Relevantdf)\n    \n    \n    \n    print(sum(Relevantdf.memory_usage()))\n    finaldf_list.append(Relevantdf)\n    Relevantdf.to_parquet('FinalData_Week' + str(n) + '.parquet')\n    \n    gc.collect()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-03T03:31:39.077626Z","iopub.execute_input":"2022-12-03T03:31:39.078067Z","iopub.status.idle":"2022-12-03T03:32:43.871333Z","shell.execute_reply.started":"2022-12-03T03:31:39.078032Z","shell.execute_reply":"2022-12-03T03:32:43.870118Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"  0%|          | 0/1 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Week 1\nmemory usage decreased by 34.4, final size 89.6 MB\nMerge-------\nMerging data...\nmemory usage decreased by 17.5, final size 0.0 MB\nmemory usage decreased by 32.0, final size 1.4 MB\nmemory usage decreased by 33.3, final size 14.4 MB\nmemory usage decreased by 7.1, final size 0.1 MB\nmemory: 383.9MB\nStandardize-------\nStandardizing data...\nGetting relative player info...\nmemory usage decreased by 8.8, final size 573.7 MB\n601549636\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1/1 [01:04<00:00, 64.78s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Final_1 = pd.read_parquet('/kaggle/working/FinalData_Week1.parquet')\n\n# Final_1.columns[50:]","metadata":{"execution":{"iopub.status.busy":"2022-12-03T03:32:49.110183Z","iopub.execute_input":"2022-12-03T03:32:49.110674Z","iopub.status.idle":"2022-12-03T03:32:50.920819Z","shell.execute_reply.started":"2022-12-03T03:32:49.110634Z","shell.execute_reply":"2022-12-03T03:32:50.919540Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# week1 = finaldf_list[0]\n\n# week1['dist_los']","metadata":{"execution":{"iopub.status.busy":"2022-12-03T01:52:55.619379Z","iopub.execute_input":"2022-12-03T01:52:55.619840Z","iopub.status.idle":"2022-12-03T01:52:55.625113Z","shell.execute_reply.started":"2022-12-03T01:52:55.619805Z","shell.execute_reply":"2022-12-03T01:52:55.624094Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Finaldf = pd.concat(finaldf_list)\n\n# Finaldf = reduce_mem_usage(Finaldf)\n\n# Finaldf.to_parquet('FinalData_2023.parquet')","metadata":{"execution":{"iopub.status.busy":"2022-11-27T09:19:46.780488Z","iopub.execute_input":"2022-11-27T09:19:46.780881Z","iopub.status.idle":"2022-11-27T09:19:47.930846Z","shell.execute_reply.started":"2022-11-27T09:19:46.780847Z","shell.execute_reply":"2022-11-27T09:19:47.929163Z"},"trusted":true},"execution_count":53,"outputs":[]}]}